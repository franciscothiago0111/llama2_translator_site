# ğŸ’» IA Local com LLaMA 2 + TraduÃ§Ã£o Offline

Este projeto demonstra como rodar uma inteligÃªncia artificial local com LLaMA 2 via Ollama e traduÃ§Ã£o via LibreTranslate, tudo 100% offline, leve e sem APIs externas.

## âœ¨ Funcionalidades

- IntegraÃ§Ã£o com LLaMA 2 para geraÃ§Ã£o de texto local
- TraduÃ§Ã£o automÃ¡tica com LibreTranslate
- Interface simples para testes
- Backend leve com JSON Server (simulaÃ§Ã£o de API)
- Tudo roda offline, sem dependÃªncias externas

## âš™ï¸ Requisitos

- Docker
- Node.js (versÃ£o 16 ou superior, para JSON Server)
- git (opcional, para clonar o repositÃ³rio)
- MÃ¡quina com pelo menos 16GB de RAM (recomendado para Ollama)
- VS Code com extensÃ£o Live Server (para executar a interface HTML)

## ğŸš€ Passo a passo

1. Clone o repositÃ³rio:
```bash
git clone https://github.com/franciscothiago0111/llama2_translator_site
cd llama2_translator_site
```

2. Baixe as imagens Docker:
```bash
docker pull ollama/ollama
docker pull libretranslate/libretranslate
```

Ou carregue manualmente (se baixado previamente):
```bash
docker load < ollama.tar
docker load < libretranslate.tar
```

3. Suba os containers:
```bash
docker run -d --name ollama -p 11434:11434 ollama/ollama
docker run -d --name libretranslate -p 5000:5000 libretranslate/libretranslate
```

â„¹ï¸ Certifique-se de que as portas 11434 (Ollama) e 5000 (LibreTranslate) estÃ£o liberadas.

4. Instale o JSON Server:
```bash
npm install -g json-server
```

5. Inicie o JSON Server no mesmo diretÃ³rio do projeto
```bash
json-server --watch db.json
```

6. Abra o arquivo HTML no VS Code e inicie o Live Server:
   - Clique com o botÃ£o direito no arquivo HTML
   - Selecione "Open with Live Server"
   - A interface serÃ¡ aberta no seu navegador padrÃ£o

## âœ… Vantagens

- ğŸ”’ Privacidade total dos dados
- ğŸš« Sem conexÃ£o com servidores externos
- ğŸ’¸ Zero custo com APIs
- âš¡ï¸ Resposta rÃ¡pida em mÃ¡quinas compatÃ­veis
- ğŸ§ª Ideal para testes, demos e desenvolvimento

## ğŸ“© Contribua
Abra issues, envie pull requests ou dÃª feedback: franciscothiago0111@gmail.com

## ğŸ§  CrÃ©ditos

- Ollama (LLaMA)
- LibreTranslate
- JSON Server
- VS Code com Live Server