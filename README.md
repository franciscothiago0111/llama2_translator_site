# AplicaÃ§Ã£o Multi-ServiÃ§os com Frontend, API REST, TraduÃ§Ã£o e IA

![Status do Projeto](https://img.shields.io/badge/status-em%20desenvolvimento-brightgreen)
![LicenÃ§a](https://img.shields.io/badge/licenÃ§a-MIT-blue)
![Docker](https://img.shields.io/badge/Docker-20.10.12+-blue)

Uma aplicaÃ§Ã£o completa com stack moderna que integra uma interface web, API REST com persistÃªncia de dados, serviÃ§o de traduÃ§Ã£o automatizada e acesso a um modelo de linguagem grande (LLM).

## ğŸ“‹ Ãndice

- [VisÃ£o Geral](#-visÃ£o-geral)
- [Arquitetura](#-arquitetura)
- [Tecnologias](#-tecnologias)
- [Requisitos](#-requisitos)
- [InstalaÃ§Ã£o e ExecuÃ§Ã£o](#-instalaÃ§Ã£o-e-execuÃ§Ã£o)
- [Uso](#-uso)
- [Estrutura do Projeto](#-estrutura-do-projeto)
- [ServiÃ§os](#-serviÃ§os)
- [PersistÃªncia de Dados](#-persistÃªncia-de-dados)
- [PersonalizaÃ§Ãµes](#-personalizaÃ§Ãµes)
- [Troubleshooting](#-troubleshooting)
- [FAQ](#-faq)
- [ContribuiÃ§Ãµes](#-contribuiÃ§Ãµes)
- [LicenÃ§a](#-licenÃ§a)

## ğŸŒŸ VisÃ£o Geral

Este projeto fornece uma infraestrutura completa e pronta para uso que inclui:

- **Frontend**: Interface web servida por Nginx
- **API REST**: JSON Server com persistÃªncia de dados
- **TraduÃ§Ã£o AutomÃ¡tica**: ServiÃ§o LibreTranslate para traduÃ§Ã£o entre idiomas
- **Modelo de IA**: Llama2 executado via Ollama para processamento de linguagem natural

Todos os componentes estÃ£o configurados em containers Docker e gerenciados via Docker Compose, garantindo uma experiÃªncia de instalaÃ§Ã£o simplificada e funcionamento idÃªntico em qualquer ambiente.

## ğŸ— Arquitetura

A aplicaÃ§Ã£o utiliza uma arquitetura de microserviÃ§os onde cada componente Ã© isolado em seu prÃ³prio container:

```
[Cliente Web] <---> [Nginx (Frontend)] <---> [JSON Server (API)]
                           â†‘                        â†‘
                           â†“                        â†“
                  [LibreTranslate] <---> [Llama2 (Modelo IA)]
```

## ğŸ›  Tecnologias

- **Frontend**: Nginx (Alpine), HTML/CSS/JavaScript
- **API**: JSON Server com Node.js
- **TraduÃ§Ã£o**: LibreTranslate (traduÃ§Ã£o de cÃ³digo aberto)
- **IA**: Ollama executando o modelo Llama2
- **Infraestrutura**: Docker e Docker Compose

## ğŸ“ Requisitos

- Docker Engine 20.10.12 ou superior
- Docker Compose v2.0.0 ou superior
- MÃ­nimo de 16GB de RAM (recomendado 32GB para melhor performance)
- MÃ­nimo de 20GB de espaÃ§o em disco

## ğŸš€ InstalaÃ§Ã£o e ExecuÃ§Ã£o

### Passo 1: Clone o repositÃ³rio

```bash
git clone https:///github.com/franciscothiago0111/llama2_translator_site.git
cd llama2_translator_site
```

### Passo 2: Inicie os containers

```bash
docker-compose up -d
```

Isso iniciarÃ¡ todos os serviÃ§os. O primeiro start pode levar alguns minutos, especialmente enquanto o Llama2 Ã© baixado.

### Passo 3: Verifique o status

```bash
docker-compose ps
```

Todos os serviÃ§os devem estar marcados como "Up".

## ğŸ“² Uso

ApÃ³s iniciar os serviÃ§os, vocÃª pode acessar:

- **Frontend**: [http://localhost:3000](http://localhost:3000)
- **API REST**: [http://localhost:3001](http://localhost:3001)
  - Exemplos:
    - Listar todos os textos: [http://localhost:3001/texts](http://localhost:3001/texts)
    - Listar todas as palavras: [http://localhost:3001/words](http://localhost:3001/words)
- **LibreTranslate**: [http://localhost:5000](http://localhost:5000)
- **Ollama/Llama2**: AcessÃ­vel via API em [http://localhost:11434](http://localhost:11434)

## ğŸ“ Estrutura do Projeto

```
projeto/
â”œâ”€â”€ docker-compose.yml          # ConfiguraÃ§Ã£o dos serviÃ§os
â”œâ”€â”€ frontend/                   # Arquivos do frontend
â”‚   â”œâ”€â”€ index.html              # PÃ¡gina principal
â”‚   â”œâ”€â”€ nginx.conf              # ConfiguraÃ§Ã£o do servidor web
â”‚   â””â”€â”€ ...                     # Outros arquivos do frontend
â”œâ”€â”€ llama2/                     # ConfiguraÃ§Ã£o do serviÃ§o Llama2
â”‚   â”œâ”€â”€ Dockerfile              # Imagem customizada para Ollama
â”‚   â””â”€â”€ init-llama.sh           # Script de inicializaÃ§Ã£o
â””â”€â”€ json-server/                # ConfiguraÃ§Ã£o do JSON Server
    â”œâ”€â”€ Dockerfile              # Imagem customizada para json-server
    â”œâ”€â”€ entrypoint.sh           # Script de inicializaÃ§Ã£o
    â”œâ”€â”€ default-db.json         # Estrutura inicial do banco de dados
    â””â”€â”€ data/                   # DiretÃ³rio para persistÃªncia de dados
        â””â”€â”€ .gitkeep            # Arquivo para manter diretÃ³rio no Git
```

## ğŸ”Œ ServiÃ§os

### Frontend (Nginx)

Serve a interface web da aplicaÃ§Ã£o. O conteÃºdo estÃ¡tico Ã© armazenado na pasta `frontend/` e servido pelo Nginx.

- **Porta**: 3000
- **Volumes**:
  - `./frontend:/usr/share/nginx/html`: Arquivos da aplicaÃ§Ã£o web
  - `./frontend/nginx.conf:/etc/nginx/conf.d/default.conf`: ConfiguraÃ§Ã£o do Nginx

### JSON Server (API REST)

Fornece uma API REST completa com operaÃ§Ãµes CRUD e persistÃªncia de dados.

- **Porta**: 3001
- **Volumes**:
  - `./json-server/data:/data`: Armazena os dados persistidos
- **Endpoints**:
  - `GET /posts`: Lista todos os posts
  - `GET /posts/:id`: ObtÃ©m um post especÃ­fico
  - `POST /posts`: Cria um novo post
  - `PUT /posts/:id`: Atualiza um post
  - `DELETE /posts/:id`: Remove um post
  - `GET /comments`: Lista todos os comentÃ¡rios
  - `GET /profile`: ObtÃ©m o perfil

### LibreTranslate

ServiÃ§o de traduÃ§Ã£o de cÃ³digo aberto que suporta diversos idiomas.

- **Porta**: 5000
- **Volumes**:
  - `libretranslate_models:/app/nllb`: Volume para armazenar modelos de traduÃ§Ã£o
- **Idiomas suportados**: InglÃªs, PortuguÃªs, Espanhol e FrancÃªs
- **Uso bÃ¡sico**: Acesse a UI em [http://localhost:5000](http://localhost:5000) ou use a API

### Llama2 (Ollama)

Modelo de linguagem grande (LLM) executado localmente via Ollama.

- **Porta**: 11434
- **Volumes**:
  - `ollama_data:/root/.ollama`: Volume para armazenar modelos de IA
- **Uso bÃ¡sico**:
  - API: `POST http://localhost:11434/api/generate`
  - Corpo da requisiÃ§Ã£o: `{"model": "llama2", "prompt": "OlÃ¡, como vocÃª estÃ¡?"}`

## ğŸ’¾ PersistÃªncia de Dados

Todos os serviÃ§os foram configurados para garantir persistÃªncia de dados entre reinicializaÃ§Ãµes:

### JSON Server

Os dados sÃ£o armazenados no diretÃ³rio `./json-server/data/`. O arquivo principal Ã© o `db.json`, que Ã© criado automaticamente na primeira inicializaÃ§Ã£o a partir do modelo `default-db.json`.

Para backup ou migraÃ§Ã£o:
```bash
cp ./json-server/data/db.json ./backup-data.json
```

### LibreTranslate

Os modelos sÃ£o armazenados em um volume Docker, permitindo que o serviÃ§o nÃ£o precise baixÃ¡-los novamente a cada inicializaÃ§Ã£o:
```bash
docker volume inspect libretranslate_models
```

### Llama2/Ollama

O modelo Llama2 e suas configuraÃ§Ãµes sÃ£o armazenados em um volume Docker:
```bash
docker volume inspect ollama_data
```

## âš™ï¸ PersonalizaÃ§Ãµes

### Modificando o Banco de Dados PadrÃ£o

Para alterar a estrutura inicial do banco de dados:

1. Edite o arquivo `json-server/default-db.json`
2. Reconstrua o container:
   ```bash
   docker-compose up -d --build json-server
   ```

### Adicionando mais idiomas ao LibreTranslate

Para suportar mais idiomas:

1. Edite o arquivo `docker-compose.yml` e modifique a variÃ¡vel de ambiente:
   ```yaml
   environment:
     - LT_LOAD_ONLY=en,pt,es,fr,de,it # Adicione os cÃ³digos de idioma desejados
   ```
2. Reinicie o serviÃ§o:
   ```bash
   docker-compose up -d libretranslate
   ```

### Usando um modelo diferente com Ollama

Para mudar o modelo de IA:

1. Edite o arquivo `llama2/init-llama.sh` e substitua "llama2" pelo modelo desejado
2. Reconstrua o container:
   ```bash
   docker-compose up -d --build llama2
   ```

## ğŸ”§ Troubleshooting

### JSON Server nÃ£o estÃ¡ persistindo dados

Verifique as permissÃµes do diretÃ³rio:
```bash
ls -la ./json-server/data/
```

O usuÃ¡rio que executa o Docker deve ter permissÃ£o de escrita neste diretÃ³rio.

### Llama2 nÃ£o estÃ¡ carregando

O download inicial do modelo pode levar tempo. Verifique os logs:
```bash
docker-compose logs -f llama2
```

### Erros de memÃ³ria com Llama2

O modelo requer bastante RAM. Aumente a memÃ³ria disponÃ­vel para o Docker no seu sistema host.

## â“ FAQ

### Ã‰ possÃ­vel executar em produÃ§Ã£o?

Esta configuraÃ§Ã£o Ã© primariamente destinada a ambientes de desenvolvimento. Para produÃ§Ã£o, seriam necessÃ¡rias configuraÃ§Ãµes adicionais de seguranÃ§a e escalabilidade.

### Como posso fazer backup dos dados?

Para cada serviÃ§o:
- **JSON Server**: Copie `./json-server/data/db.json`
- **LibreTranslate/Llama2**: FaÃ§a backup dos volumes Docker

### Como atualizar os serviÃ§os?

```bash
git pull                    # Atualiza os arquivos do repositÃ³rio
docker-compose pull         # Puxa as imagens mais recentes
docker-compose up -d --build # ReconstrÃ³i e reinicia os containers
```

## ğŸ‘¥ ContribuiÃ§Ãµes

ContribuiÃ§Ãµes sÃ£o bem-vindas! Por favor, siga estas etapas:

1. FaÃ§a um fork do repositÃ³rio
2. Crie uma branch para sua feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova funcionalidade'`)
4. Push para a branch (`git push origin feature/nova-funcionalidade`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ licenciado sob a LicenÃ§a MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

---

Desenvolvido com â¤ï¸ por [Francisco Thiago]

Para suporte ou dÃºvidas, abra uma [issue](https:///github.com/franciscothiago0111/llama2_translator_site/issues) no GitHub.